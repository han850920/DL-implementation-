{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cl import conv_layer\n",
    "\n",
    "\n",
    "class CNN(object):\n",
    "    def __init__(self,\n",
    "                input_data_spec = [10,3,28,28],\n",
    "                conv_layer_spec = [{\"k_num\":2,\n",
    "                                    \"k_h\":3,\n",
    "                                    \"k_w\":3,\n",
    "                                    \"stride\":1,\n",
    "                                    \"zp\":0,\n",
    "                                    \"maxPoolingHeight\":2,\n",
    "                                    \"maxPoolingWidth\":2}],\n",
    "                fc_layer_spec=[100,50,10]):\n",
    "        \n",
    "        #conv layer list\n",
    "        self.cnn_net = []\n",
    "        for i in range(len(conv_layer_spec)):\n",
    "            self.cnn_net.append(cl(bs = input_data_spec[0],\n",
    "                                           i_ch = input_data_spec[1],\n",
    "                                           i_h = input_data_spec[2],\n",
    "                                           i_w = input_data_spec[3],\n",
    "                                           k_num = conv_layer_spec[i][\"k_num\"],\n",
    "                                           k_h = conv_layer_spec[i][\"k_h\"],\n",
    "                                           k_w = conv_layer_spec[i][\"k_w\"],\n",
    "                                           stride = conv_layer_spec[i][\"stride\"],\n",
    "                                           zp = conv_layer_spec[i][\"zp\"],\n",
    "                                           maxPoolingHeight = conv_layer_spec[i][\"maxPoolingHeight\"],\n",
    "                                           maxPoolingWidth = conv_layer_spec[i][\"maxPoolingWidth\"]))\n",
    "            input_data_spec = list(self.cnn_net[i].ao.shape)\n",
    "        \n",
    "        \n",
    "        (bs,ch,r,c) = self.cnn_net[-1].ao.shape # last layer of CNN and connect to fully-connected layer\n",
    "        fc_layer_spec[0] = ch * r * c\n",
    "        self.fc_net = MLP(Layers = fc_layer_spec, BatchSize = input_data_spec[0])\n",
    "        return\n",
    "    \n",
    "    def forward(self,input_data):\n",
    "        \n",
    "        #forward the net\n",
    "        for i in range(len(self.cnn_net)):\n",
    "            if i == 0:\n",
    "                np.copyto(self.cnn_net[i].ai,input_data)\n",
    "            else:\n",
    "                np.copyto(self.cnn_net[i].ai, self.cnn_net[i-1].ao)\n",
    "            self.cnn_net[i].forward()\n",
    "        \n",
    "        #flatten the last layer and forwad to MLP \n",
    "        input_data_fc = np.copy(self.cnn_net[-1].ao.reshape(self.cnn_net[-1].ao.shape[0],-1).T)\n",
    "        self.fc_net.forward(input_data_fc)\n",
    "    \n",
    "    def backprop(self):\n",
    "        \n",
    "        #MLP backprop\n",
    "        self.fc_net.backprop()\n",
    "        #transfer the gradient from MLP to the CNN\n",
    "        np.copyto(self.cnn_net[-1].dJdao,\n",
    "                  self.fc_net.net[0].dJdi.T.reshape(self.cnn_net[-1].dJdao.shape))\n",
    "        #CNN backprop\n",
    "        for i in range(len(self.cnn_net)-1,-1,-1):\n",
    "            self.cnn_net[i].backprop()\n",
    "            \n",
    "            if i>0:\n",
    "                np.copyto(self.cnn_net[i-1].dJdao,self.cnn_net[i].dJdai)\n",
    "        return\n",
    "    \n",
    "    def update(self,lr,eta):\n",
    "        #update the weight of every conv layer\n",
    "        for i in range(len(self.cnn_net)):\n",
    "            self.cnn_net[i].update(lr,eta)\n",
    "        self.fc_net.update(lr,eta)\n",
    "        return\n",
    "    \n",
    "    def train(self, train_x, train_y, val_x, val_y, epoch_cnt, lr, eta):\n",
    "        for e in range(epoch_cnt):\n",
    "            #shufle the input_data\n",
    "            shuffle = np.arange(train_x.shape[0])#得一個 0~len(train_x)-1 且 順序打亂的序列\n",
    "            train_x_s = train_x[shuffle] #再照順序給 可得shuffle後的結果\n",
    "            train_y_s = train_y[shuffle]\n",
    "            bs = self.fc_net.bs\n",
    "            for i in range(train_x_s.shape[0]//bs):\n",
    "                \n",
    "                x = train_x_s[i*bs:(i+1)*bs,:,:,:]\n",
    "                y = train_y_s[i*bs:(i+1)*bs]\n",
    "                self.forward(x)\n",
    "                self.fc_net.loss(y,eta)\n",
    "                self.backprop()\n",
    "                self.update(lr,eta)\n",
    "\n",
    "                \n",
    "                #output the procedure\n",
    "                print(\"\\nEpoch:\",e,\"Batch: \",i, \"J=\",self.fc_net.J[-1],\n",
    "                      \"Error Rate: \",np.count_nonzero(np.array(y-self.fc_net.yhat)/float(len(y))))\n",
    "                print(\"\\n Proper learn rate: \",lr )\n",
    "                print (\"\\nMax abs(a) of Last MLP Layer=\", np.max(np.abs(self.fc_net.net[-1].a)), \n",
    "                       \"\\nMax abs(dJda) of Last MLP Layer=\", np.max(np.abs(self.fc_net.net[-1].dJda)),\n",
    "                      \"\\nMax abs(W) of Last MLP Layer=\", np.max(np.abs(self.fc_net.net[1].W)), \"\\n\")\n",
    "            \n",
    "            #Validation\n",
    "            for i in range(val_x.shape[0]//bs):\n",
    "                x = val_x[i*bs:(i+1)*bs,:,:,:]\n",
    "                y = val_y[i*bs:(i+1)*bs]\n",
    "                self.forward(x)\n",
    "                self.fc_net.loss_val(y,eta)\n",
    "        return  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
